{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an RAG chatbot\n",
    "\n",
    "By [Purinat Pattanakeaw](<https://www.github.com/Purinat33>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Preprocessing\n",
    "\n",
    "* Remove misc. contents like document's title in footer of every page using tools like `fitz`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Reading data\n",
    "\n",
    "Using `SimpleDirectoryReader` which reads an entire directory, including files like images, PDFs etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/understanding/loading/loading/\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# We will be reading it in the storage steps\n",
    "# documents = SimpleDirectoryReader(\"../docs\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model\n",
    "\n",
    "Using `sentence-transformers` Embedding Model via HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings/\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Caching model\n",
    "# https://python.langchain.com/v0.2/docs/how_to/caching_embeddings/\n",
    "# https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.huggingface.HuggingFaceEmbeddings.html\n",
    "store = LocalFileStore('cache')\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    hf, store, namespace=model_name\n",
    ")\n",
    "\n",
    "Settings.embed_model = LangchainEmbedding(embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/understanding/loading/loading/\n",
    "# https://medium.com/@kofsitho/basic-tutorial-rag-with-llama-index-8927a5716dd1\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "Settings.splitter = SentenceSplitter(chunk_size=512, chunk_overlap=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Storage and Persistent Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage exists at ./persist/: Loading\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "import os\n",
    "\n",
    "# We moved the loading logic of loading documents here so we can check for persistent\n",
    "# Check if persistent storage exists, if so: load from there.\n",
    "persist_dir = './persist/'\n",
    "if os.path.exists(persist_dir) and len(os.listdir(persist_dir)) > 0:\n",
    "    print(f\"Storage exists at {persist_dir}: Loading\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir='./persist/')\n",
    "    index = load_index_from_storage(storage_context=storage_context)\n",
    "else:   \n",
    "    print(f\"{persist_dir} not exists: Performing loading\")\n",
    "    documents = SimpleDirectoryReader(\"../docs\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    index.storage_context.persist(persist_dir=persist_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set defeault retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.609\n",
      "Content:\n",
      " P1: IOI\n",
      "WY001-01 WY001-Bolsover-v2.cls September 16, 2003 10:24\n",
      "8 CELLS AND TISSUES\n",
      "The Electron Microscope\n",
      "The most commonly used type of electron microscope in biology is called the transmis-\n",
      "sion electron microscope because electrons are transmitted through the specimen to the\n",
      "observer. The transmission electron microscope has essentially the same design as a light\n",
      "microscope, but the lenses, rather than being glass, are electromagnets that bend beamsof electrons (Fig. 1.3 b). An electron gun generates a beam of electrons by heating a thin,\n",
      "V-shaped piece of tungsten wire to 3000\n",
      "◦C. A large voltage accelerates the beam down\n",
      "the microscope column, which is under vacuum because the electrons would be slowedand scattered if they collided with air molecules. The magni ﬁed image can be viewed on a\n",
      "ﬂuorescent screen that emits light when struck by electrons. While the electron microscope\n",
      "offers great improvements in resolution, electron beams are potentially highly destructive,and biological material must be subjected to a complex processing schedule before it canbe examined. The preparation of cells for electron microscopy is summarized in Figure 1.6.\n",
      "A small piece of tissue (~1 mm3) is immersed in glutaraldehyde \n",
      "and osmium tetroxide. These chemicals bind all the component \n",
      "parts of the cells together; the tissue is said to be fixed . It is \n",
      "then washed thoroughly.\n",
      "The tissue is dehydrated  by soaking in acetone or ethanol.\n",
      "The tissue is embedded  in resin which is then baked hard.\n",
      "Sections (thin slices less than 100 nm thick) are \n",
      "cut with a machine called an ultramicrotome.\n",
      "The sections are placed on a small copper grid  and \n",
      "stained with uranyl acetate and lead citrate. When \n",
      "viewed in the electron microscope, regions that have bound lots of uranium and lead will appear dark because they are a barrier to the electron beam.\n",
      "Figure 1.6. Preparation of tissue for electron microscopy.\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@kofsitho/basic-tutorial-rag-with-llama-index-8927a5716dd1\n",
    "base_retriever = index.as_retriever(similarity_top_k=3)\n",
    "source_nodes = base_retriever.retrieve(\"Microscope\")\n",
    "print(f\"Score: {source_nodes[0].score:.3f}\")\n",
    "print(f\"Content:\\n {source_nodes[0].get_content()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
